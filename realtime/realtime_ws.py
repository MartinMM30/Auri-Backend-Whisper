# realtime/realtime_ws.py

import io
import json
import logging
import wave

from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from openai import AsyncOpenAI

from auribrain.auri_mind import AuriMind

# -------------------------------------------------------
# LOGGING PROFESIONAL (se ve en logs de Railway)
# -------------------------------------------------------
logger = logging.getLogger("uvicorn.error")

router = APIRouter()
client = AsyncOpenAI()          # Usa OPENAI_API_KEY de las env vars
auri = AuriMind()               # Motor de pensamiento de Auri

STT_MODEL = "whisper-1"
TTS_MODEL = "gpt-4o-mini-tts"
VOICE_ID = "alloy"              # âš ï¸ Voz vÃ¡lida por defecto
SAMPLE_RATE = 16000


# -------------------------------------------------------
# PCM â†’ WAV
# -------------------------------------------------------
def pcm16_to_wav(pcm_bytes: bytes, sample_rate: int):
    buffer = io.BytesIO()
    with wave.open(buffer, "wb") as wav:
        wav.setnchannels(1)
        wav.setsampwidth(2)          # 16-bit PCM
        wav.setframerate(sample_rate)
        wav.writeframes(pcm_bytes)
    buffer.seek(0)
    return buffer


# -------------------------------------------------------
# SESSION
# -------------------------------------------------------
class RealtimeSession:
    def __init__(self):
        self.pcm_buffer = bytearray()

    def append_pcm(self, data: bytes):
        self.pcm_buffer.extend(data)

    def clear(self):
        self.pcm_buffer = bytearray()


# -------------------------------------------------------
# WEBSOCKET
# -------------------------------------------------------
@router.websocket("/realtime")
async def realtime_socket(ws: WebSocket):
    await ws.accept()
    logger.info("ðŸ”Œ Cliente conectado al WS /realtime")

    session = RealtimeSession()

    try:
        while True:
            msg = await ws.receive()

            # Bytes = audio PCM del micro
            if msg.get("bytes") is not None:
                session.append_pcm(msg["bytes"])
                continue

            # Texto JSON
            if msg.get("text") is not None:
                try:
                    data = json.loads(msg["text"])
                except Exception:
                    logger.warning("âš  JSON invÃ¡lido recibido en WS")
                    continue

                await handle_json(ws, session, data)

    except WebSocketDisconnect:
        logger.info("âŒ Cliente desconectado de /realtime")
    except Exception as e:
        logger.exception("ðŸ”¥ ERROR en WS principal: %s", e)


# -------------------------------------------------------
# HANDLER DE MENSAJES JSON
# -------------------------------------------------------
async def handle_json(ws: WebSocket, session: RealtimeSession, msg: dict):
    t = msg.get("type")

    # Handshake inicial
    if t == "client_hello":
        await ws.send_json({"type": "hello_ok"})
        logger.info("ðŸ™‹ HELLO: %s", msg)

    # Inicio de sesiÃ³n de voz
    elif t == "start_session":
        logger.info("ðŸŽ¤ Inicio de sesiÃ³n de voz")
        session.clear()
        # El mÃ³vil ya pone el slime en 'listening'; aquÃ­ no marcamos thinking todavÃ­a.

    # Fin de audio: procesar STT + AuriMind + TTS
    elif t == "audio_end":
        await process_stt_tts(ws, session)

    # Comando por texto (teclado)
    elif t == "text_command":
        txt = (msg.get("text") or "").strip()
        if not txt:
            return
        await process_text_only(ws, txt)

    # Ping opcional
    elif t == "ping":
        await ws.send_json({"type": "pong"})


# -------------------------------------------------------
# PIPELINE COMPLETO: PCM -> STT -> AuriMind -> TTS
# -------------------------------------------------------
async def process_stt_tts(ws: WebSocket, session: RealtimeSession):
    if len(session.pcm_buffer) == 0:
        logger.info("ðŸŽ™ SesiÃ³n sin audio, nada que transcribir")
        await ws.send_json({"type": "thinking", "state": False})
        await ws.send_json({"type": "tts_end"})
        return

    logger.info("ðŸŽ™ Recibidos %d bytes PCM", len(session.pcm_buffer))
    await ws.send_json({"type": "thinking", "state": True})

    try:
        # ------- PCM â†’ WAV ----------
        wav = pcm16_to_wav(session.pcm_buffer, SAMPLE_RATE)
        wav.name = "audio.wav"

        # --------------- STT ---------------------
        logger.info("ðŸ§  Whisper STTâ€¦")
        stt = await client.audio.transcriptions.create(
            model=STT_MODEL,
            file=wav,
        )

        text = (getattr(stt, "text", "") or "").strip()
        logger.info("ðŸ“ Texto STT: %s", text)

        await ws.send_json({"type": "stt_final", "text": text})

        if not text:
            await ws.send_json({
                "type": "reply_final",
                "text": "No escuchÃ© nada claro, Â¿puedes repetirlo?"
            })
            return

        # --------------- AuriMind (pensar respuesta) -----------
        reply = await think_with_auri(text)

        # --------------- TTS + envÃ­o ---------------------------
        await send_tts_reply(ws, reply)

    except Exception as e:
        logger.exception("ðŸ”¥ Error en pipeline STT+LLM+TTS: %s", e)
        await ws.send_json({
            "type": "reply_final",
            "text": "Lo siento, tuve un problema interno al procesar tu voz."
        })
    finally:
        await ws.send_json({"type": "thinking", "state": False})
        await ws.send_json({"type": "tts_end"})
        session.clear()


# -------------------------------------------------------
# MODO SOLO TEXTO (sin audio de entrada)
# -------------------------------------------------------
async def process_text_only(ws: WebSocket, user_text: str):
    logger.info("âœ‰ Texto directo recibido: %s", user_text)
    await ws.send_json({"type": "thinking", "state": True})

    try:
        reply = await think_with_auri(user_text)
        await send_tts_reply(ws, reply)
    except Exception:
        logger.exception("ðŸ”¥ Error en pipeline solo texto")
        await ws.send_json({
            "type": "reply_final",
            "text": "Lo siento, tuve un problema interno al pensar tu respuesta."
        })
    finally:
        await ws.send_json({"type": "thinking", "state": False})
        await ws.send_json({"type": "tts_end"})


# -------------------------------------------------------
# AuriMind: pensar respuesta
# -------------------------------------------------------
async def think_with_auri(user_text: str) -> str:
    try:
        result = auri.think(user_text) or {}
        reply = (result.get("final") or result.get("raw") or "").strip()

        if not reply:
            reply = (
                "Lo siento, no supe quÃ© responder exactamente, "
                "pero seguirÃ© aprendiendo de ti."
            )

        logger.info("ðŸ§  AuriMind reply: %s", reply)
        return reply

    except Exception as e:
        logger.exception("ðŸ”¥ Error en AuriMind.think: %s", e)
        return "Lo siento, tuve un problema interno al pensar tu respuesta."


# -------------------------------------------------------
# TTS STREAMING (MP3 â€” compatible 100% con Railway)
# -------------------------------------------------------
async def send_tts_reply(ws: WebSocket, text: str):
    logger.info("ðŸ”Š TTS reply: %s", text)

    # Enviar texto al cliente (UI)
    await ws.send_json({"type": "reply_partial", "text": text[:80]})
    await ws.send_json({"type": "reply_final", "text": text})

    # === TTS MP3 (sin PCM16, sin sample rate, sin formato) ===
    try:
        # Stream MP3 desde la API moderna (sin format ni sample_rate)
        response = await client.audio.speech.with_streaming_response.create(
            model=TTS_MODEL,   # gpt-4o-mini-tts
            voice=VOICE_ID,    # alloy
            input=text         # texto a convertir
        )

        async with response:
            async for chunk in response.iter_bytes():
                # El chunk ya es MP3 raw
                await ws.send_bytes(chunk)

        logger.info("âœ… Respuesta TTS (MP3) enviada por streaming")

    except Exception as e:
        logger.exception("ðŸ”¥ Error generando TTS: %s", e)
        # Mostramos solo el texto final; audio no es obligatorio
        await ws.send_json({
            "type": "tts_error",
            "error": str(e)
        })

